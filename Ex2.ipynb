{"cells":[{"cell_type":"markdown","metadata":{"id":"xhBRQ277nP69"},"source":["# Homework 2 - Generalized Hough Transform"]},{"cell_type":"markdown","metadata":{"id":"KbO36k-SnP69"},"source":["## Theory\n","\n","< Insert your answers here >"]},{"cell_type":"markdown","metadata":{"id":"dSgl8cBBnP6-"},"source":["## Programming"]},{"cell_type":"markdown","metadata":{"id":"SRB1C27mnP6-"},"source":["Find object in an image using a template:  \n","![title](data/template.jpg)\n","![title](data/query.jpg)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"LmJV0VFwnP6-","executionInfo":{"status":"error","timestamp":1717393750263,"user_tz":-120,"elapsed":388,"user":{"displayName":"Hsin Tang (Ashin)","userId":"08489995315091703313"}},"outputId":"4b7ecc73-1b25-4f02-89f4-25ef365a1259"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'utils'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-cfa92e9f163e>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# -*- coding: utf-8 -*-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["#!/usr/bin/env python3\n","# -*- coding: utf-8 -*-\n","import cv2\n","import utils\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from sklearn.metrics.pairwise import euclidean_distances\n","\n","def nonMaxSuprression(img, d=5):\n","    \"\"\"\n","    Given an image set all values to 0 that are not\n","    the maximum in its (2d+1,2d+1)-window\n","\n","    Parameters\n","    ----------\n","    img : ndarray\n","        an image\n","    d : int\n","        for each pixel consider the surrounding (2d+1,2d+1)-window\n","\n","    Returns\n","    -------\n","    result : ndarray\n","    \"\"\"\n","    rows, cols = img.shape\n","    result = np.zeros((rows, cols))\n","    for i in range(d, rows-d):\n","        for j in range(d, cols-d):\n","            local_max = np.max(img[i-d:i+d+1, j-d:j+d+1])\n","            if img[i, j] == local_max:\n","                result[i, j] = img[i, j]\n","    return result\n","\n","def calcBinaryMask(img, thresh=0.3):\n","    \"\"\"\n","    Compute the gradient of an image and compute a binary mask\n","    based on the threshold. Corresponds to O^B in the slides.\n","\n","    Parameters\n","    ----------\n","    img : ndarray\n","        an image\n","    thresh : float\n","        A threshold value. The default is 0.3.\n","\n","    Returns\n","    -------\n","    binary : ndarray\n","        A binary image.\n","    \"\"\"\n","    # Compute gradients\n","    grad_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n","    grad_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n","    gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n","\n","    # Threshold gradients\n","    binary = np.zeros_like(gradient_magnitude)\n","    binary[gradient_magnitude > thresh] = 1\n","\n","    return binary\n","\n","def correlation(img, template):\n","    \"\"\"\n","    Compute a correlation of gradients between an image and a template.\n","\n","    Note:\n","    You should use the formula in the slides using the fourier transform.\n","    Then you are guaranteed to succeed.\n","\n","    However, you can also compute the correlation directly.\n","    The resulting image must have high positive values at positions\n","    with high correlation.\n","\n","    Parameters\n","    ----------\n","    img : ndarray\n","        a grayscale image\n","    template : ndarray\n","        a grayscale image of the template\n","\n","    Returns\n","    -------\n","    ndarray\n","        an image containing the correlation between image and template gradients.\n","    \"\"\"\n","    # Compute gradient of the image\n","    grad_x_img = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n","    grad_y_img = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n","    gradient_img = np.sqrt(grad_x_img**2 + grad_y_img**2)\n","\n","    # Compute gradient of the template\n","    grad_x_template = cv2.Sobel(template, cv2.CV_64F, 1, 0, ksize=3)\n","    grad_y_template = cv2.Sobel(template, cv2.CV_64F, 0, 1, ksize=3)\n","    gradient_template = np.sqrt(grad_x_template**2 + grad_y_template**2)\n","\n","    # Copy template gradient into larger frame\n","    template_padded = np.zeros_like(gradient_img)\n","    template_padded[:gradient_template.shape[0], :gradient_template.shape[1]] = gradient_template\n","\n","    # Apply a circular shift\n","    template_padded = np.roll(template_padded, -gradient_template.shape[0]//2, axis=0)\n","    template_padded = np.roll(template_padded, -gradient_template.shape[1]//2, axis=1)\n","\n","    # Normalize template\n","    template_padded /= np.linalg.norm(template_padded)\n","\n","    # Compute correlation using Fourier transform\n","    corr = cv2.filter2D(gradient_img, -1, template_padded)\n","\n","    return corr\n","\n","def GeneralizedHoughTransform(img, template, angles, scales):\n","    \"\"\"\n","    Compute the generalized hough transform. Given an image and a template.\n","\n","    Parameters\n","    ----------\n","    img : ndarray\n","        A query image\n","    template : ndarray\n","        a template image\n","    angles : list[float]\n","        A list of angles provided in degrees\n","    scales : list[float]\n","        A list of scaling factors\n","\n","    Returns\n","    -------\n","    hough_table : list[(correlation, angle, scaling)]\n","        The resulting hough table is a list of tuples.\n","        Each tuple contains the correlation and the corresponding combination\n","        of angle and scaling factors of the template.\n","\n","        Note the order of these values.\n","    \"\"\"\n","    hough_table = []\n","    for angle in angles:\n","        for scale in scales:\n","            # Rotate and scale template\n","            rows, cols = template.shape\n","            M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, scale)\n","            rotated_scaled_template = cv2.warpAffine(template, M, (cols, rows))\n","\n","            # Compute the correlation\n","            corr = correlation(img, rotated_scaled_template)\n","\n","            # Store results with parameters in a list\n","            hough_table.append((corr, angle, scale))\n","\n","    return hough_table\n"]},{"cell_type":"markdown","metadata":{"id":"YF-vCUqKnP6-"},"source":["# Main Program"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"du5Q6qeknP6-","executionInfo":{"status":"aborted","timestamp":1717393750263,"user_tz":-120,"elapsed":3,"user":{"displayName":"Hsin Tang (Ashin)","userId":"08489995315091703313"}}},"outputs":[],"source":["# Load query image and template\n","query = cv2.imread(\"data/query.jpg\", cv2.IMREAD_GRAYSCALE)\n","template = cv2.imread(\"data/template.jpg\", cv2.IMREAD_GRAYSCALE)\n","\n","# Visualize images\n","utils.show(query)\n","utils.show(template)\n","\n","# Create search space and compute GHT\n","angles = np.linspace(0, 360, 36)\n","scales = np.linspace(0.9, 1.3, 10)\n","ght = GeneralizedHoughTransform(query, template, angles, scales)\n","\n","# extract votes (correlation) and parameters\n","votes, thetas, s = zip(*ght)\n","\n","# Visualize votes\n","print(\"Hough votes\")\n","votes = np.stack(votes).max(0)\n","plt.imshow(votes)\n","plt.show()\n","\n","# nonMaxSuprression\n","print(\"Filtered Hough votes\")\n","votes = nonMaxSuprression(votes, 20)\n","plt.imshow(votes)\n","plt.show()\n","\n","# Visualize n best matches\n","n = 10\n","coords = zip(*np.unravel_index(np.argpartition(votes, -n, axis=None)[-n:], votes.shape))\n","vis = np.stack(3*[query],2)\n","print(\"Detected Positions\")\n","for y,x in coords:\n","    print(x,y)\n","    vis = cv2.circle(vis,(x,y), 10, (255,0,0), 2)\n","utils.show(vis)\n"]},{"cell_type":"markdown","metadata":{"id":"L93Am5JfnP6_"},"source":["# Test your implementation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Azvg23ynP6_","executionInfo":{"status":"aborted","timestamp":1717393750263,"user_tz":-120,"elapsed":3,"user":{"displayName":"Hsin Tang (Ashin)","userId":"08489995315091703313"}}},"outputs":[],"source":["import utils\n","import cv2\n","import json\n","from matplotlib import pyplot as plt\n","import numpy as np\n","from sklearn.metrics.pairwise import euclidean_distances\n","\n","\n","def testGHT():\n","    # Load Images\n","    query = cv2.imread(\"data/query.jpg\", cv2.IMREAD_GRAYSCALE)\n","    template = cv2.imread(\"data/template.jpg\", cv2.IMREAD_GRAYSCALE)\n","\n","    # GHT with search space\n","    angles = np.linspace(0, 360, 36)\n","    scales = np.linspace(0.9, 1.3, 10)\n","    ght = GeneralizedHoughTransform(query, template, angles, scales)\n","\n","    # Visualize GHT votes\n","    votes, thetas, s = zip(*ght)\n","    votes = np.stack(votes).max(0)\n","    plt.imshow(votes)\n","    plt.show()\n","\n","    # Visualize filtered points\n","    votes = nonMaxSuprression(votes, 20)\n","    plt.imshow(votes)\n","    plt.show()\n","\n","    # Extract n points wiht highest voting score\n","    n = 10\n","    coords = list(zip(*np.unravel_index(np.argpartition(votes, -n, axis=None)[-n:], votes.shape)))\n","    vis = np.stack(3*[query],2)\n","    for y,x in coords:\n","        vis = cv2.circle(vis,(x,y), 10, (255,0,0), 2)\n","    utils.show(vis)\n","\n","    # Compare with ground-truth centroids\n","    f = open(\"centroids.txt\", \"r\")\n","    centroids = f.read()\n","    f.close()\n","    centroids = centroids.split(\"\\n\")[:-1]\n","    centroids = [centroid.split() for centroid in centroids]\n","    centroids = np.array([[int(centroid[0]),int(centroid[1])] for centroid in centroids])\n","\n","    # Visualize centroids\n","    vis = np.stack(3*[query],2)\n","    for x,y in centroids:\n","        vis = cv2.circle(vis,(x,y), 10, (255,0,0), 2)\n","    utils.show(vis)\n","\n","    # Compute Distances and apply threshold\n","    coords = np.array(coords)[:,::-1]\n","    d = euclidean_distances(centroids, coords).min(1)\n","    correct_detections = np.count_nonzero((d<10))\n","    score = { \"scores\": {\"Correct_Detections\": correct_detections }}\n","\n","    print(json.dumps(score))\n","\n","testGHT()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}